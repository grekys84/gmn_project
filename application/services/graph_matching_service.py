import csv
import json
import logging
import time
from dataclasses import dataclass, asdict
from datetime import datetime
from pathlib import Path
from typing import Optional

import networkx as nx
import torch
import torch.nn.functional as F
from torch_geometric.data import Data

from infrastructure.scripts.svg_parser import svg_to_graph
from infrastructure.utils.visualization import svg_overlay
from domain.models.siamese_gnn import SiameseGNN
from infrastructure.utils.match_graph import match_graph
from infrastructure.scripts.geometry_compare import geometry_compare_slow
from domain.config.settings import settings


logger = logging.getLogger("GraphMatchingService")


# ============================================================
#                   –ò–°–ö–õ–Æ–ß–ï–ù–ò–Ø
# ============================================================

class MissingModelError(RuntimeError):
    """–í–æ–∑–Ω–∏–∫–∞–µ—Ç, –∫–æ–≥–¥–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏."""


class MissingDatabaseError(RuntimeError):
    """–í–æ–∑–Ω–∏–∫–∞–µ—Ç, –∫–æ–≥–¥–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –±–∞–∑–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤."""


# ============================================================
#                   –†–ï–ó–£–õ–¨–¢–ê–¢ –°–†–ê–í–ù–ï–ù–ò–Ø
# ============================================================

@dataclass
class MatchResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞."""

    id: Optional[str] = None
    source: Optional[str] = None
    percent: float = 0.0
    valid: bool = False
    reason: Optional[str] = None

    def __repr__(self) -> str:
        return (
            f"<MatchResult id={self.id} valid={self.valid} "
            f"percent={self.percent:.2f} reason={self.reason}>"
        )

    def to_dict(self) -> dict:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –æ–±—ä–µ–∫—Ç –≤ —Å–ª–æ–≤–∞—Ä—å."""
        return asdict(self)


# ============================================================
#                   –û–°–ù–û–í–ù–û–ô –°–ï–†–í–ò–°
# ============================================================

class GraphMatchingService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è SVG-–≥—Ä–∞—Ñ–æ–≤ —Å–æ —Å–ø—Ä–∞–≤–æ—á–Ω–æ–π –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö."""

    def __init__(
        self,
        top_k: Optional[int] = None,
        threshold: Optional[float] = None,
        model_path: Optional[Path] = None,
        embedding_db_path: Optional[Path] = None,
        overlay_dir: Optional[Path] = None,
    ) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤."""
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # –ü—É—Ç–∏
        self.model_path = model_path or Path(settings.models.current_model) / "GMN_v1.0.0.pt"
        self.embedding_db_path = embedding_db_path or Path(settings.service.embedding_db_path)
        self.graph_db_dir = Path(settings.data.master_graph)
        self.overlay_dir = overlay_dir or Path(settings.data.overlays)

        self.db_emb_path = self.embedding_db_path / "db_embeddings.pt"
        self.db_meta_path = self.embedding_db_path / "db_meta.json"

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        self.top_k = top_k or settings.service.top_k
        self.threshold = threshold or settings.service.similarity_threshold
        self.slow_geometry_threshold = settings.geometry.slow_threshold
        self.max_node_mismatch_percent = settings.geometry.max_node_mismatch_percent
        self.max_edge_mismatch_percent = settings.geometry.max_edge_mismatch_percent
        self.max_bbox_mismatch_percent = settings.geometry.max_bbox_mismatch_percent

        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        if not self.model_path.exists():
            raise MissingModelError(f"Model file not found: {self.model_path}")
        if self.model_path.is_dir():
            raise MissingModelError(f"Model path is a directory: {self.model_path}")

        self.model = SiameseGNN(embed_dim=128).to(self.device)
        state_dict = torch.load(self.model_path, map_location=self.device, weights_only=False)
        if "state_dict" in state_dict:
            state_dict = state_dict["state_dict"]
        self.model.load_state_dict(state_dict)
        self.model.eval()

        # –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã
        if not self.db_emb_path.exists() or not self.db_meta_path.exists():
            raise MissingDatabaseError("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –±–∞–∑–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.")

        self.db_embeddings = torch.load(self.db_emb_path, map_location=self.device, weights_only=False)
        with self.db_meta_path.open("r", encoding="utf-8") as f:
            self.db_meta = json.load(f)

        if len(self.db_meta) == 0 or self.db_embeddings.size(0) == 0:
            raise MissingDatabaseError("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.")

        self.db_embeddings = F.normalize(self.db_embeddings, p=2, dim=1)

        # –û—Ç—á—ë—Ç
        self.log_dir = settings.logging.log_dir
        self.report_path = self.log_dir / "endpoint.csv"
        if not self.report_path.exists():
            with self.report_path.open("w", newline="", encoding="utf-8") as f:
                writer = csv.writer(f)
                writer.writerow(["timestamp", "input_filename", "matched_id", "matched_source", "similarity_percent", "valid", "candidate_nodes", "candidate_edges", "candidate_width_mm", "candidate_height_mm", "candidate_area_mm2"])

    # ============================================================
    #                   –û–°–ù–û–í–ù–û–ô –ú–ï–¢–û–î
    # ============================================================

    def predict_path(self, svg_path: Path, filename: Optional[str] = None) -> dict:
        """–ù–∞—Ö–æ–¥–∏—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–π –≥—Ä–∞—Ñ –∏–∑ –±–∞–∑—ã –ø–æ SVG-—Ñ–∞–π–ª—É."""
        filename = filename or svg_path.name
        logger.info(f"–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ SVG-—Ñ–∞–π–ª–∞: {svg_path}")
        start_total = time.perf_counter()

        nx_graph = self._parse_svg(svg_path)
        data, pred_nx = self._graph_from_nx(nx_graph)
        matches = self._find_embedding_matches(data)
        best_result = self._select_best_match(pred_nx, matches)
        overlay_path = self._generate_overlay(pred_nx, best_result)
        self._write_report(filename, best_result, overlay_path, start_total)

        logger.info(
            f"–§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {best_result.source or '‚Äî'}, "
            f"—Å—Ö–æ–¥—Å—Ç–≤–æ {best_result.percent:.2f}%, valid={best_result.valid}"
        )

        return {
            "id": best_result.source,
            "similarity_percent": round(best_result.percent, 2),
            "overlay_path": str(overlay_path) if overlay_path else None,
            "valid": best_result.valid,
        }

    # ============================================================
    #                   –û–ë–Å–†–¢–ö–ê –î–õ–Ø –ë–ê–ô–¢–û–í
    # ============================================================

    def predict_bytes(self, file_bytes: bytes, filename: str = "uploaded.svg") -> dict:
        """–ü—Ä–∏–Ω–∏–º–∞–µ—Ç SVG-—Ñ–∞–π–ª –≤ –≤–∏–¥–µ –±–∞–π—Ç–æ–≤ –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ."""
        logger.info(f"–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {filename}, —Ä–∞–∑–º–µ—Ä: {len(file_bytes)} –±–∞–π—Ç")

        from tempfile import NamedTemporaryFile
        import os

        with NamedTemporaryFile(suffix=".svg", delete=False) as tmp:
            tmp.write(file_bytes)
            tmp_path = Path(tmp.name)

        try:
            return self.predict_path(tmp_path, filename=filename)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ predict_bytes –¥–ª—è {filename}: {e}", exc_info=True)
            raise
        finally:
            try:
                os.unlink(tmp_path)
            except (OSError, FileNotFoundError):
                pass

    # ============================================================
    #                   –ü–ê–†–°–ò–ù–ì –ò –ì–†–ê–§
    # ============================================================

    def _parse_svg(self, svg_path: Path) -> nx.Graph:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç SVG-—Ñ–∞–π–ª –≤ –≥—Ä–∞—Ñ NetworkX –∏ –ª–æ–≥–∏—Ä—É–µ—Ç –±–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã."""
        try:
            start = time.perf_counter()
            nx_graph = svg_to_graph(svg_path)
            elapsed = time.perf_counter() - start

            num_nodes = nx_graph.number_of_nodes()
            num_edges = nx_graph.number_of_edges()
            width_mm = nx_graph.graph.get("width_mm", 0)
            height_mm = nx_graph.graph.get("height_mm", 0)
            area_mm2 = nx_graph.graph.get("area_mm2", 0)

            logger.info(f"SVG –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω: {num_nodes} —É–∑–ª–æ–≤, {num_edges} —Ä—ë–±–µ—Ä (–∑–∞ {elapsed:.2f} —Å)")
            logger.info(f"–ì–∞–±–∞—Ä–∏—Ç—ã –¥–µ—Ç–∞–ª–∏: {width_mm:.3f} √ó {height_mm:.3f} –º–º (–ø–ª–æ—â–∞–¥—å: {area_mm2:.3f} –º–º¬≤)")
            return nx_graph
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ SVG {svg_path}: {e}")
            raise ValueError(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ SVG: {e}")

    def _graph_from_nx(self, nx_graph: nx.Graph) -> tuple[Data, nx.Graph]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≥—Ä–∞—Ñ NetworkX –≤ PyTorch Geometric Data –∏ –æ–±—Ä–∞—Ç–Ω–æ."""
        x = torch.tensor([[nx_graph.nodes[n]["x"], nx_graph.nodes[n]["y"]] for n in nx_graph.nodes], dtype=torch.float)
        edge_index = torch.tensor(list(nx_graph.edges), dtype=torch.long).t().contiguous()
        data = Data(x=x, edge_index=edge_index)
        return data, self._data_to_networkx(data)

    def _find_embedding_matches(self, data: Data) -> list[dict]:
        """–ù–∞—Ö–æ–¥–∏—Ç –±–ª–∏–∂–∞–π—à–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≥—Ä–∞—Ñ–æ–≤ –∏–∑ –±–∞–∑—ã."""
        start = time.perf_counter()
        matches = match_graph(data, master_db=(self.db_embeddings, self.db_meta), top_k=self.top_k, threshold=None)
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(matches)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–∑–∞ {time.perf_counter() - start:.2f} —Å)")
        return matches

    # ============================================================
    #                   –ü–†–û–í–ï–†–ö–ê –ö–ê–ù–î–ò–î–ê–¢–û–í
    # ============================================================

    def _select_best_match(self, pred_nx: nx.Graph, matches: list[dict]) -> MatchResult:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–π."""
        pred_stats = self._graph_measurements(pred_nx)
        best = MatchResult()
        for item in matches:
            result = self._evaluate_candidate(item, pred_nx, pred_stats)
            if result.valid:
                return result
        logger.info("–í—Å–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –æ—Ç–∫–ª–æ–Ω–µ–Ω—ã, —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return best

    def _generate_overlay(self, pred_nx: nx.Graph, best_result: MatchResult) -> Optional[Path]:
        """–°–æ–∑–¥–∞—ë—Ç SVG-–æ–≤–µ—Ä–ª–µ–π –º–µ–∂–¥—É –∏—Å—Ö–æ–¥–Ω—ã–º –≥—Ä–∞—Ñ–æ–º –∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–º."""
        if not best_result.valid or not best_result.id:
            return None
        self.overlay_dir.mkdir(parents=True, exist_ok=True)
        overlay_path = self.overlay_dir / f"{best_result.id}_overlay.svg"
        cand_nx = self._load_candidate_graph(best_result.id)
        if cand_nx:
            svg_overlay(pred_nx, cand_nx, overlay_path)
            logger.info(f"–û–≤–µ—Ä–ª–µ–π —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {overlay_path}")
            return overlay_path
        return None

    def _evaluate_candidate(self, item: dict, pred_nx: nx.Graph, pred_stats: dict) -> MatchResult:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–¥–Ω–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ (GNN + –≥–µ–æ–º–µ—Ç—Ä–∏—è) —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
        cand_id = item["id"]
        cand_meta = next((m for m in self.db_meta if m["id"] == cand_id), {})
        cand_source = cand_meta.get("source", "unknown_source")
        sim_percent = item["similarity_percent"]

        logger.info(f" ‚ñ∂Ô∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞: {cand_id} ({cand_source}) ")
        logger.info(f"GNN —Å—Ö–æ–¥—Å—Ç–≤–æ {sim_percent:.2f}%")

        if sim_percent < self.threshold:
            logger.info(f"–ü—Ä–æ–ø—É—Å–∫ {cand_id} ({cand_source}) ‚Äî –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞ GNN ({self.threshold:.1f}%)")
            return MatchResult(id=cand_id, source=cand_source, reason="gnn_threshold")

        cand_nx = self._load_candidate_graph(cand_id)
        if cand_nx is None:
            return MatchResult(id=cand_id, source=cand_source, reason="load_failed")

        cand_stats = self._graph_measurements(cand_nx)

        # --- –õ–æ–≥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤ ---
        node_diff = self._percentage_diff(pred_stats["nodes"], cand_stats["nodes"])
        edge_diff = self._percentage_diff(pred_stats["edges"], cand_stats["edges"])
        width_diff = self._percentage_diff(pred_stats["width"], cand_stats["width"])
        height_diff = self._percentage_diff(pred_stats["height"], cand_stats["height"])
        area_diff = self._percentage_diff(pred_stats["area"], cand_stats["area"])
        logger.info(
            f"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤: —É–∑–ª—ã {pred_stats['nodes']}‚Üí{cand_stats['nodes']} (Œî {node_diff:.2f}%), "
            f"—Ä—ë–±—Ä–∞ {pred_stats['edges']}‚Üí{cand_stats['edges']} (Œî {edge_diff:.2f}%), "
            f"—à–∏—Ä–∏–Ω–∞ {pred_stats['width']:.1f}‚Üí{cand_stats['width']:.1f} (Œî {width_diff:.2f}%), "
            f"–≤—ã—Å–æ—Ç–∞ {pred_stats['height']:.1f}‚Üí{cand_stats['height']:.1f} (Œî {height_diff:.2f}%), "
            f"–ø–ª–æ—â–∞–¥—å {pred_stats['area']:.1f}‚Üí{cand_stats['area']:.1f} (Œî {area_diff:.2f}%)"
        )

        size_reason = self._validate_geometry_size(pred_stats, cand_stats)
        if size_reason:
            logger.info(f" üî¥ –û—Ç–∫–∞–∑ {cand_id} ({cand_source}) ‚Äî –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤: {size_reason}")
            return MatchResult(id=cand_id, source=cand_source, reason="geometry_size")

        try:
            result = geometry_compare_slow(
                pred_nx, cand_nx,
                tol=settings.geometry.tol,
                angle_tol=settings.geometry.angle_tol,
                use_angles=settings.geometry.use_angles,
                normalize_position=settings.geometry.normalize_position,
                normalize_scale=settings.geometry.normalize_scale,
                feature_weights=settings.geometry.feature_weights,
                feature_coverage_importance=(
                    settings.geometry.feature_coverage_importance
                ),
            )
            if isinstance(result, dict):
                score = result.get("score", 0.0)
                node_match = result.get("node_match", 0.0)
                edge_match = result.get("edge_match", 0.0)
                logger.info(f"–ì–µ–æ–º–µ—Ç—Ä–∏—è: —Å—Ö–æ–¥—Å—Ç–≤–æ {score:.2f}%, —É–∑–ª—ã {node_match:.2f}%, —Ä—ë–±—Ä–∞ {edge_match:.2f}%")
            else:
                score = float(result)
                logger.info(f"–ì–µ–æ–º–µ—Ç—Ä–∏—è: —Å—Ö–æ–¥—Å—Ç–≤–æ {score:.2f}%")

            if score >= self.slow_geometry_threshold:
                logger.info(f"‚úÖ –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ: {cand_id} ({cand_source})")
                return MatchResult(id=cand_id, source=cand_source, percent=score, valid=True)
            return MatchResult(id=cand_id, source=cand_source, percent=score, reason="geometry_mismatch")

        except Exception as e:
            logger.warning(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è {cand_id}: {e}")
            return MatchResult(id=cand_id, source=cand_source, reason="geometry_exception")

    def _write_report(
            self,
            filename: str,
            best_result: MatchResult,
            overlay_path: Optional[Path],
            start_total: float) -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–ø–∏—Å—å –≤ CSV-–æ—Ç—á—ë—Ç —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–∏."""
        try:
            # --- –ª–æ–≥–∏—Ä—É–µ–º –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ ---
            if best_result and best_result.valid:
                cand_nx = self._load_candidate_graph(best_result.id)
                if cand_nx:
                    cand_stats = self._graph_measurements(cand_nx)
                    logger.info(
                        f"–§–∏–Ω–∞–ª—å–Ω—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç: {best_result.id} ({best_result.source}) | "
                        f"—É–∑–ª—ã={cand_stats['nodes']}, —Ä—ë–±—Ä–∞={cand_stats['edges']}, "
                        f"—à–∏—Ä–∏–Ω–∞={cand_stats['width']:.2f} –º–º, –≤—ã—Å–æ—Ç–∞={cand_stats['height']:.2f} –º–º, "
                        f"–ø–ª–æ—â–∞–¥—å={cand_stats['area']:.1f} –º–º¬≤"
                    )
                else:
                    cand_stats = {"nodes": 0, "edges": 0, "width": 0.0, "height": 0.0, "area": 0.0}
            else:
                cand_stats = {"nodes": 0, "edges": 0, "width": 0.0, "height": 0.0, "area": 0.0}

            # --- –∑–∞–ø–∏—Å—å –≤ CSV ---
            with self.report_path.open("a", newline="", encoding="utf-8") as f:
                writer = csv.writer(f)
                writer.writerow([
                    datetime.now().isoformat(),
                    filename,
                    best_result.id or "",
                    best_result.source or "",
                    round(best_result.percent, 2),
                    best_result.valid,
                    cand_stats["nodes"],
                    cand_stats["edges"],
                    round(cand_stats["width"], 2),
                    round(cand_stats["height"], 2),
                    round(cand_stats["area"], 2),
                ])

            logger.info(
                f"–ó–∞–ø–∏—Å—å –≤ CSV –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (–≤—Ä–µ–º—è: {time.perf_counter() - start_total:.2f} —Å), "
                f"–¥–æ–±–∞–≤–ª–µ–Ω—ã –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–∞."
            )

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –æ—Ç—á—ë—Ç–∞: {e}", exc_info=True)

    # ============================================================
    #                   –í–ê–õ–ò–î–ê–¶–ò–Ø –†–ê–ó–ú–ï–†–û–í
    # ============================================================

    def _validate_geometry_size(self, pred_stats: dict, cand_stats: dict) -> Optional[str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –±–∞–∑–æ–≤—ã–µ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (—É–∑–ª—ã, —Ä—ë–±—Ä–∞, bbox, –ø–ª–æ—â–∞–¥—å)."""
        node_diff = self._percentage_diff(pred_stats["nodes"], cand_stats["nodes"])
        if node_diff > self.max_node_mismatch_percent:
            return f"—Ä–∞–∑–Ω–∏—Ü–∞ –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —É–∑–ª–æ–≤ {node_diff:.2f}%"

        edge_diff = self._percentage_diff(pred_stats["edges"], cand_stats["edges"])
        if edge_diff > self.max_edge_mismatch_percent:
            return f"—Ä–∞–∑–Ω–∏—Ü–∞ –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —Ä—ë–±–µ—Ä {edge_diff:.2f}%"

        width_diff = self._percentage_diff(pred_stats["width"], cand_stats["width"])
        height_diff = self._percentage_diff(pred_stats["height"], cand_stats["height"])
        area_diff = self._percentage_diff(pred_stats["area"], cand_stats["area"])
        bbox_diff = max(width_diff, height_diff, area_diff)
        if bbox_diff > self.max_bbox_mismatch_percent:
            return f"–æ—Ç–ª–∏—á–∏–µ –≥–∞–±–∞—Ä–∏—Ç–æ–≤/–ø–ª–æ—â–∞–¥–∏ {bbox_diff:.2f}%"

        abs_width_diff = abs(pred_stats["width"] - cand_stats["width"])
        abs_height_diff = abs(pred_stats["height"] - cand_stats["height"])
        abs_area_diff = abs(pred_stats["area"] - cand_stats["area"])
        max_abs_width = settings.geometry.max_absolute_bbox_diff_mm
        max_abs_area = settings.geometry.max_absolute_area_diff_mm2

        if abs_width_diff > max_abs_width or abs_height_diff > max_abs_width:
            return f"–∞–±—Å–æ–ª—é—Ç–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –≥–∞–±–∞—Ä–∏—Ç–æ–≤ {abs_width_diff:.2f}√ó{abs_height_diff:.2f} –º–º (–¥–æ–ø—É—Å–∫ ¬±{max_abs_width:.1f} –º–º)"
        if abs_area_diff > max_abs_area:
            return f"–∞–±—Å–æ–ª—é—Ç–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –ø–ª–æ—â–∞–¥–∏ {abs_area_diff:.1f} –º–º¬≤ (–¥–æ–ø—É—Å–∫ ¬±{max_abs_area:.0f} –º–º¬≤)"

        ratio_pred = pred_stats["width"] / max(pred_stats["height"], 1e-9)
        ratio_cand = cand_stats["width"] / max(cand_stats["height"], 1e-9)
        ratio_diff = self._percentage_diff(ratio_pred, ratio_cand)
        if ratio_diff > 10.0:
            return f"–Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–π (—à–∏—Ä–∏–Ω–∞/–≤—ã—Å–æ—Ç–∞) {ratio_diff:.1f}%"
        return None

    # ============================================================
    #                   –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –£–¢–ò–õ–ò–¢–´
    # ============================================================

    @staticmethod
    def _data_to_networkx(data: Data) -> nx.Graph:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç PyTorch Geometric Data –≤ NetworkX-–≥—Ä–∞—Ñ."""
        g = nx.Graph()
        for i in range(data.x.size(0)):
            x, y = data.x[i].tolist()
            g.add_node(int(i), x=float(x), y=float(y), pos=(float(x), float(y)))
        edges = data.edge_index.t().tolist()
        g.add_edges_from(edges)
        return g

    @staticmethod
    def _graph_measurements(graph: nx.Graph) -> dict[str, float]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –±–∞–∑–æ–≤—ã–µ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≥—Ä–∞—Ñ–∞."""
        nodes = graph.number_of_nodes()
        edges = graph.number_of_edges()
        xs = [float(graph.nodes[n].get("x", 0.0)) for n in graph.nodes]
        ys = [float(graph.nodes[n].get("y", 0.0)) for n in graph.nodes]
        if xs and ys:
            width, height = max(xs) - min(xs), max(ys) - min(ys)
        else:
            width = height = 0.0
        area = width * height
        return {"nodes": nodes, "edges": edges, "width": width, "height": height, "area": area}

    @staticmethod
    def _percentage_diff(a: float, b: float) -> float:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—É—é —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É a –∏ b –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö."""
        baseline = max(abs(a), abs(b), 1e-9)
        return abs(a - b) / baseline * 100.0

    def _load_candidate_graph(self, candidate_id: str) -> Optional[nx.Graph]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≥—Ä–∞—Ñ-–∫–∞–Ω–¥–∏–¥–∞—Ç –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ ID."""
        cand_path = self.graph_db_dir / f"{candidate_id}.pt"
        if not cand_path.exists():
            logger.warning(f"–§–∞–π–ª –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {cand_path}")
            return None
        try:
            cand_data = torch.load(cand_path, weights_only=False)
            return self._data_to_networkx(cand_data)
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ {candidate_id}: {e}")
            return None
